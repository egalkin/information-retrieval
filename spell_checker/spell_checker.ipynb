{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import collections\n",
    "import Levenshtein\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "russian_word_pattern = re.compile('^[а-яА-Я]+$')\n",
    "\n",
    "def is_russian(word):\n",
    "    return russian_word_pattern.match(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "operation_probability = collections.defaultdict(int)\n",
    "action_probability = collections.defaultdict(int)\n",
    "dependent_probability = collections.defaultdict(int)\n",
    "\n",
    "def count_word_mutation(word, expected_word):\n",
    "    edit_ops = Levenshtein.editops(word, expected_word)\n",
    "    edit_indexes = set(map(lambda op: op[1], edit_ops))\n",
    "    mutation = []\n",
    "    cur_edit_pos = 0\n",
    "    for i in range(len(word)):\n",
    "        if i not in edit_indexes:\n",
    "            mutation.append(('replace', word[i], word[i]))\n",
    "        else:\n",
    "            cur_edit = edit_ops[cur_edit_pos]\n",
    "            if cur_edit[0] == 'replace':\n",
    "                mutation.append(('replace', word[cur_edit[1]], expected_word[cur_edit[2]]))\n",
    "            elif cur_edit[0] == 'delete':\n",
    "                mutation.append(('delete', word[cur_edit[1]]))\n",
    "            else:\n",
    "                mutation.append(('insert', expected_word[cur_edit[2]]))\n",
    "    return mutation\n",
    "\n",
    "def count_probabilities(word_mutation):\n",
    "    prev_op = None\n",
    "    for mut in word_mutation:\n",
    "        operation_probability[mut[0]] += 1\n",
    "        action_probability[mut] += 1\n",
    "        dependent_probability[(prev_op, mut)] += 1\n",
    "        prev_op = mut\n",
    "        \n",
    "\n",
    "def build_error_model():\n",
    "    with codecs.open(\"train.csv\", 'r', 'utf8') as train:\n",
    "        train.readline()\n",
    "        i = 0\n",
    "        for line in train:\n",
    "            word, expected_word = line.split(',')\n",
    "            word, expected_word = word.strip(), expected_word.strip()\n",
    "            if (is_russian(word)):\n",
    "                word_mutation = count_word_mutation(word, expected_word)\n",
    "                count_probabilities(word_mutation)\n",
    "                \n",
    "\n",
    "build_error_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrieNode(object):\n",
    "    def __init__(self, char):\n",
    "        self.char = char\n",
    "        self.children = []\n",
    "        self.terminal = False\n",
    "        self.word = None\n",
    "        self.freq = None\n",
    "    \n",
    "    def set_frequency(self, freq):\n",
    "        self.freq = freq\n",
    "\n",
    "    def set_word(self, word):\n",
    "        self.word = word\n",
    "    \n",
    "\n",
    "def add(root, word, freq):\n",
    "    node = root\n",
    "    for char in word:\n",
    "        found_in_child = False\n",
    "        for child in node.children:\n",
    "            if child.char == char:\n",
    "                node = child\n",
    "                found_in_child = True\n",
    "                break\n",
    "        if not found_in_child:\n",
    "            new_node = TrieNode(char)\n",
    "            node.children.append(new_node)\n",
    "            node = new_node\n",
    "    node.terminal = True\n",
    "    node.set_frequency(freq)\n",
    "    node.set_word(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_freq = collections.defaultdict(int)\n",
    "\n",
    "def build_trie():\n",
    "    root = TrieNode(\"*\")\n",
    "    with codecs.open('words.csv', 'r', 'utf8') as words:\n",
    "        words.readline()\n",
    "        for line in words:\n",
    "            processed_line = line.split(',')\n",
    "            word, freq = processed_line[0].strip(), int(processed_line[1].strip())\n",
    "            if is_russian(word):\n",
    "                add(root, word, freq)\n",
    "                words_freq[word] = freq\n",
    "    return root\n",
    "            \n",
    "trie = build_trie()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_ratio(fix, word):\n",
    "    return words_freq[fix] / words_freq[word]\n",
    "\n",
    "def best_ratio(fix1, fix2):\n",
    "    return words_freq[fix1] / words_freq[fix2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "b = 0.95\n",
    "c = 0.05\n",
    "top = 3\n",
    "fix_ratio_threshold = 5.0\n",
    "best_ratio_threshold = 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter, attrgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_correction_probability(correction, prev_op):\n",
    "    return a * operation_probability[correction[0]] +\\\n",
    "           b * action_probability[correction] +\\\n",
    "           c * dependent_probability[(prev_op, correction)]\n",
    "    \n",
    "    \n",
    "def fix_word(root, word, fix_variants, prev_op = None, corrections_num = 0):\n",
    "    if corrections_num > 1:\n",
    "        return\n",
    "    if not root.terminal and not word:\n",
    "        return\n",
    "    if root.terminal and not word:\n",
    "        fix_variants.append((root.word, root.freq))\n",
    "        return\n",
    "    corrections = []\n",
    "    cur_char = word[0] \n",
    "    for idx in range(len(root.children)):\n",
    "        child = root.children[idx]\n",
    "        if (len(word) >= 4) or (cur_char == child.char):\n",
    "            corrections.append(('replace', cur_char, child.char, idx))    \n",
    "    corrections_probs = list(map(lambda cor: compute_correction_probability(cor[0:3], prev_op), corrections))\n",
    "    corrections_statistic = sorted(list(zip(corrections, corrections_probs)), key=itemgetter(1), reverse=True)\n",
    "    top_corrections = corrections_statistic[0:top]\n",
    "    for correction, _ in top_corrections:\n",
    "        cur_char, fixed_char, idx = correction[1:4]\n",
    "        next_node = root.children[idx]\n",
    "        fix_word(next_node, word[1:], fix_variants, correction[0:3],\n",
    "                 corrections_num if cur_char == fixed_char else corrections_num + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_word(word):\n",
    "    if is_russian(word):\n",
    "        fix_variants = []\n",
    "        fix_word(trie, word , fix_variants)\n",
    "        best_fixes = sorted(fix_variants, key = itemgetter(1), reverse = True)\n",
    "        result = best_fixes[0] if fix_ratio(best_fixes[0][0], word) >= fix_ratio_threshold else word\n",
    "        if len(best_fixes) > 1:\n",
    "            result = best_fixes[0][0] if best_ratio(best_fixes[0][0], best_fixes[1][0]) >= best_ratio_threshold else word\n",
    "        return result\n",
    "    else:\n",
    "        return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17268\n"
     ]
    }
   ],
   "source": [
    "fixed = 0\n",
    "\n",
    "with codecs.open('no_fix.submission.csv', 'r', 'utf8') as file:\n",
    "    with codecs.open('submission.csv', 'w', 'utf8') as submission:\n",
    "        header = file.readline()\n",
    "        submission.write(header)\n",
    "        for line in file:\n",
    "            processed_line = line.split(',')\n",
    "            word = processed_line[0]\n",
    "            if is_russian(word):\n",
    "                fixed_word = process_word(word)\n",
    "                if fixed_word != word:\n",
    "                    fixed += 1\n",
    "                submission.write(f'{word},{fixed_word}\\n')\n",
    "            else:\n",
    "                submission.write(line)\n",
    "\n",
    "print(fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
